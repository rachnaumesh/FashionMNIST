{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "rRJZf-Rq5zzP",
        "outputId": "a811ec42-fcc4-439e-f239-c59c1f2ec659"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: torch in /usr/local/lib/python3.10/dist-packages (2.4.0+cu121)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from torch) (3.16.0)\n",
            "Requirement already satisfied: typing-extensions>=4.8.0 in /usr/local/lib/python3.10/dist-packages (from torch) (4.12.2)\n",
            "Requirement already satisfied: sympy in /usr/local/lib/python3.10/dist-packages (from torch) (1.13.2)\n",
            "Requirement already satisfied: networkx in /usr/local/lib/python3.10/dist-packages (from torch) (3.3)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.10/dist-packages (from torch) (3.1.4)\n",
            "Requirement already satisfied: fsspec in /usr/local/lib/python3.10/dist-packages (from torch) (2024.6.1)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.10/dist-packages (from jinja2->torch) (2.1.5)\n",
            "Requirement already satisfied: mpmath<1.4,>=1.1.0 in /usr/local/lib/python3.10/dist-packages (from sympy->torch) (1.3.0)\n",
            "Requirement already satisfied: torchvision in /usr/local/lib/python3.10/dist-packages (0.19.0+cu121)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.10/dist-packages (from torchvision) (1.26.4)\n",
            "Requirement already satisfied: torch==2.4.0 in /usr/local/lib/python3.10/dist-packages (from torchvision) (2.4.0+cu121)\n",
            "Requirement already satisfied: pillow!=8.3.*,>=5.3.0 in /usr/local/lib/python3.10/dist-packages (from torchvision) (9.4.0)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from torch==2.4.0->torchvision) (3.16.0)\n",
            "Requirement already satisfied: typing-extensions>=4.8.0 in /usr/local/lib/python3.10/dist-packages (from torch==2.4.0->torchvision) (4.12.2)\n",
            "Requirement already satisfied: sympy in /usr/local/lib/python3.10/dist-packages (from torch==2.4.0->torchvision) (1.13.2)\n",
            "Requirement already satisfied: networkx in /usr/local/lib/python3.10/dist-packages (from torch==2.4.0->torchvision) (3.3)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.10/dist-packages (from torch==2.4.0->torchvision) (3.1.4)\n",
            "Requirement already satisfied: fsspec in /usr/local/lib/python3.10/dist-packages (from torch==2.4.0->torchvision) (2024.6.1)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.10/dist-packages (from jinja2->torch==2.4.0->torchvision) (2.1.5)\n",
            "Requirement already satisfied: mpmath<1.4,>=1.1.0 in /usr/local/lib/python3.10/dist-packages (from sympy->torch==2.4.0->torchvision) (1.3.0)\n",
            "Requirement already satisfied: matplotlib in /usr/local/lib/python3.10/dist-packages (3.7.1)\n",
            "Requirement already satisfied: contourpy>=1.0.1 in /usr/local/lib/python3.10/dist-packages (from matplotlib) (1.3.0)\n",
            "Requirement already satisfied: cycler>=0.10 in /usr/local/lib/python3.10/dist-packages (from matplotlib) (0.12.1)\n",
            "Requirement already satisfied: fonttools>=4.22.0 in /usr/local/lib/python3.10/dist-packages (from matplotlib) (4.53.1)\n",
            "Requirement already satisfied: kiwisolver>=1.0.1 in /usr/local/lib/python3.10/dist-packages (from matplotlib) (1.4.7)\n",
            "Requirement already satisfied: numpy>=1.20 in /usr/local/lib/python3.10/dist-packages (from matplotlib) (1.26.4)\n",
            "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.10/dist-packages (from matplotlib) (24.1)\n",
            "Requirement already satisfied: pillow>=6.2.0 in /usr/local/lib/python3.10/dist-packages (from matplotlib) (9.4.0)\n",
            "Requirement already satisfied: pyparsing>=2.3.1 in /usr/local/lib/python3.10/dist-packages (from matplotlib) (3.1.4)\n",
            "Requirement already satisfied: python-dateutil>=2.7 in /usr/local/lib/python3.10/dist-packages (from matplotlib) (2.8.2)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.10/dist-packages (from python-dateutil>=2.7->matplotlib) (1.16.0)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.10/dist-packages (1.26.4)\n",
            "Requirement already satisfied: torchsummary in /usr/local/lib/python3.10/dist-packages (1.5.1)\n"
          ]
        }
      ],
      "source": [
        "!pip install torch\n",
        "!pip install torchvision\n",
        "!pip install matplotlib\n",
        "!pip install numpy\n",
        "!pip install torchsummary"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 12,
      "metadata": {
        "id": "Xs2D_RSouNVL"
      },
      "outputs": [],
      "source": [
        "import os\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.optim as optim\n",
        "import torchvision\n",
        "import torchvision.transforms as transforms\n",
        "import matplotlib.pyplot as plt\n",
        "import numpy as np\n",
        "from torch.nn import functional as F"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 13,
      "metadata": {
        "id": "AC7cOzcPrke1"
      },
      "outputs": [],
      "source": [
        "#Load and preprocess the Fashion-MNIST dataset from torchvision rather than using the file on canvas (same dataset)\n",
        "transform = transforms.Compose([\n",
        "    transforms.ToTensor(),\n",
        "    transforms.Normalize((0.5,), (0.5,))\n",
        "])\n",
        "\n",
        "#Splitting the data into train and test splits\n",
        "train_dataset = torchvision.datasets.FashionMNIST(root='./data', train=True, download=True, transform=transform)\n",
        "test_dataset = torchvision.datasets.FashionMNIST(root='./data', train=False, download=True, transform=transform)\n",
        "\n",
        "#Load data\n",
        "train_loader = torch.utils.data.DataLoader(train_dataset, batch_size=64, shuffle=True)\n",
        "test_loader = torch.utils.data.DataLoader(test_dataset, batch_size=64, shuffle=False)\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "data_iter = iter(train_loader)\n",
        "images, labels = next(data_iter)\n",
        "\n",
        "# Print the shape of the images\n",
        "print(f\"Image batch shape: {images.shape}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "8isjsQwIjHGS",
        "outputId": "7201d7a2-d588-4ebd-df54-c822dcec8cc9"
      },
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Image batch shape: torch.Size([64, 1, 28, 28])\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 15,
      "metadata": {
        "id": "bzCk892CrJNs"
      },
      "outputs": [],
      "source": [
        "#Define the LeNet-5 architecture based upon LeCun et al., 1998\n",
        "class LeNet5(nn.Module):\n",
        "    def __init__(self):\n",
        "        super(LeNet5, self).__init__()\n",
        "        self.conv1 = nn.Conv2d(1, 6, kernel_size=5, padding=2)\n",
        "        self.conv2 = nn.Conv2d(6, 16, kernel_size=5)\n",
        "        self.fc1 = nn.Linear(16 * 5 * 5, 120)\n",
        "        self.fc2 = nn.Linear(120, 84)\n",
        "        self.fc3 = nn.Linear(84, 10)\n",
        "\n",
        "    def forward(self, x):\n",
        "        x = torch.relu(self.conv1(x))\n",
        "        x = torch.max_pool2d(x, 2)\n",
        "        x = torch.relu(self.conv2(x))\n",
        "        x = torch.max_pool2d(x, 2)\n",
        "        x = x.view(-1, 16 * 5 * 5)\n",
        "        x = torch.relu(self.fc1(x))\n",
        "        x = torch.relu(self.fc2(x))\n",
        "        x = self.fc3(x)\n",
        "        return x\n",
        "\n",
        "#Checking if a GPU with Cuda is available\n",
        "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "\n",
        "\n",
        "#Initialize the model, loss function, and optimizer\n",
        "model = LeNet5().to(device)\n",
        "criterion = nn.CrossEntropyLoss()\n",
        "optimizer = optim.Adam(model.parameters(), lr=0.001)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 16,
      "metadata": {
        "id": "YK-PJ75JrEmV"
      },
      "outputs": [],
      "source": [
        "#Define the LeNet-5 architecture based upon LeCun et al., 1998 with dropout and batch normalization\n",
        "class LeNet5Regularized(nn.Module):\n",
        "    def __init__(self, dropout_rate=0.5, use_bn=False):\n",
        "        super(LeNet5Regularized, self).__init__()\n",
        "        self.conv1 = nn.Conv2d(1, 6, kernel_size=5, padding=2)\n",
        "        self.conv2 = nn.Conv2d(6, 16, kernel_size=5)\n",
        "        self.fc1 = nn.Linear(16 * 5 * 5, 120)\n",
        "        self.fc2 = nn.Linear(120, 84)\n",
        "        self.fc3 = nn.Linear(84, 10)\n",
        "        self.dropout = nn.Dropout(dropout_rate)\n",
        "        self.use_bn = use_bn\n",
        "        if use_bn:\n",
        "            self.bn1 = nn.BatchNorm2d(6)\n",
        "            self.bn2 = nn.BatchNorm2d(16)\n",
        "\n",
        "#1. Test using bn before relu and only doing dropout after first fully connected layer\n",
        "#2. Test using bn after relu and dropout after second fully connected layer as well\n",
        "    def forward(self, x):\n",
        "        x = self.conv1(x)\n",
        "        if self.use_bn:\n",
        "            x = self.bn1(x)\n",
        "        x = F.relu(x)\n",
        "        x = F.max_pool2d(x, 2)\n",
        "        x = self.conv2(x)\n",
        "        if self.use_bn:\n",
        "            x = self.bn2(x)\n",
        "        x = F.relu(x)\n",
        "        x = F.max_pool2d(x, 2)\n",
        "        x = x.view(-1, 16 * 5 * 5)\n",
        "        x = F.relu(self.fc1(x))\n",
        "        x = self.dropout(x)\n",
        "        x = F.relu(self.fc2(x))\n",
        "        x = self.dropout(x)\n",
        "        x = self.fc3(x)\n",
        "        return x"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Training and evaluation function for all epochs\n",
        "def train_and_evaluate(model, train_loader, test_loader, optimizer, criterion, num_epochs, device):\n",
        "    train_accuracies = []\n",
        "    test_accuracies = []\n",
        "    best_test_accuracy = 0.0\n",
        "    best_epoch = 0\n",
        "\n",
        "    # Loop over epochs\n",
        "    for epoch in range(num_epochs):\n",
        "        model.train()\n",
        "        train_correct = 0\n",
        "        train_total = 0\n",
        "\n",
        "        # Go through all training data\n",
        "        for images, labels in train_loader:\n",
        "            images, labels = images.to(device), labels.to(device)\n",
        "            optimizer.zero_grad()\n",
        "            outputs = model(images)\n",
        "            loss = criterion(outputs, labels)\n",
        "            loss.backward()\n",
        "            optimizer.step()\n",
        "\n",
        "            _, predicted = torch.max(outputs.data, 1)\n",
        "            train_total += labels.size(0)\n",
        "            train_correct += (predicted == labels).sum().item()\n",
        "\n",
        "        # Calculate train accuracy for epoch\n",
        "        train_accuracy = 100 * train_correct / train_total\n",
        "        train_accuracies.append(train_accuracy)\n",
        "\n",
        "        # Evaluate\n",
        "        model.eval()\n",
        "        test_correct = 0\n",
        "        test_total = 0\n",
        "\n",
        "        # Go through all test data\n",
        "        with torch.no_grad():\n",
        "            for images, labels in test_loader:\n",
        "                images, labels = images.to(device), labels.to(device)\n",
        "                outputs = model(images)\n",
        "                _, predicted = torch.max(outputs.data, 1)\n",
        "                test_total += labels.size(0)\n",
        "                test_correct += (predicted == labels).sum().item()\n",
        "\n",
        "        # Calculate test accuracy for epoch\n",
        "        test_accuracy = 100 * test_correct / test_total\n",
        "        test_accuracies.append(test_accuracy)\n",
        "\n",
        "        print(f'Epoch [{epoch+1}/{num_epochs}], Train Accuracy: {train_accuracy:.2f}%, Test Accuracy: {test_accuracy:.2f}%')\n",
        "\n",
        "        # Check if this is the best accuracy so far\n",
        "        if test_accuracy > best_test_accuracy:\n",
        "            best_test_accuracy = test_accuracy\n",
        "            best_epoch = epoch + 1\n",
        "\n",
        "    return train_accuracies, test_accuracies, best_test_accuracy, best_epoch"
      ],
      "metadata": {
        "id": "L__V-Hed_GmU"
      },
      "execution_count": 17,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Hyperparameter definitions\n",
        "num_epochs = 20\n",
        "learning_rate = 0.001\n",
        "weight_decay = 1e-4\n",
        "dropout_rate = 0.5\n",
        "\n",
        "# Directory to save the best model weights\n",
        "save_dir = './saved_models/'\n",
        "os.makedirs(save_dir, exist_ok=True)\n",
        "\n",
        "# Train and evaluate different models\n",
        "models = {\n",
        "    'Base Model': LeNet5().to(device),\n",
        "    'Dropout': LeNet5Regularized(dropout_rate=dropout_rate).to(device),\n",
        "    'Weight Decay': LeNet5().to(device),\n",
        "    'Batch Normalization': LeNet5Regularized(dropout_rate=0, use_bn=True).to(device)\n",
        "}\n",
        "\n",
        "results = {}\n",
        "\n",
        "# Train and save best weights\n",
        "for name, model in models.items():\n",
        "    print(f\"\\nTraining {name} model:\")\n",
        "\n",
        "    if name == 'Weight Decay':\n",
        "        optimizer = optim.Adam(model.parameters(), lr=learning_rate, weight_decay=weight_decay)\n",
        "    else:\n",
        "        optimizer = optim.Adam(model.parameters(), lr=learning_rate)\n",
        "\n",
        "    # Subdirectory for each model's weights\n",
        "    model_save_dir = os.path.join(save_dir, name.lower().replace(\" \", \"_\"))\n",
        "    os.makedirs(model_save_dir, exist_ok=True)\n",
        "    best_model_path = os.path.join(model_save_dir, 'best_model.pth')\n",
        "\n",
        "    # Train the model and get accuracies and the best epoch\n",
        "    train_accuracies, test_accuracies, best_test_accuracy, best_epoch = train_and_evaluate(\n",
        "        model, train_loader, test_loader, optimizer, criterion, num_epochs, device\n",
        "    )\n",
        "\n",
        "    # Save the best model\n",
        "    torch.save(model.state_dict(), best_model_path)\n",
        "    print(f\"Best model for {name} saved with test accuracy: {best_test_accuracy:.2f}% at epoch {best_epoch}\")\n",
        "\n",
        "    # Store results for plotting and summarizing\n",
        "    results[name] = {\n",
        "        'train': train_accuracies,\n",
        "        'test': test_accuracies,\n",
        "        'best_test_accuracy': best_test_accuracy,\n",
        "        'best_epoch': best_epoch\n",
        "    }\n",
        "\n",
        "\n",
        "# Plotting based on format defined in assignment\n",
        "plt.figure(figsize=(20, 15))\n",
        "for i, (name, accuracies) in enumerate(results.items()):\n",
        "    plt.subplot(2, 2, i+1)\n",
        "    plt.plot(range(1, num_epochs+1), accuracies['train'], label='Train')\n",
        "    plt.plot(range(1, num_epochs+1), accuracies['test'], label='Test')\n",
        "    plt.title(f'{name}')\n",
        "    plt.xlabel('Epochs')\n",
        "    plt.ylabel('Accuracy (%)')\n",
        "    plt.legend()\n",
        "\n",
        "# Saving all charts to a file\n",
        "plt.tight_layout()\n",
        "plt.savefig('convergence_graphs-2.png')\n",
        "plt.close()\n",
        "\n",
        "# Create a summary table for the losses both train and test\n",
        "summary_table = {\n",
        "    'Model': [],\n",
        "    'Final Train Accuracy (%)': [],\n",
        "    'Final Test Accuracy (%)': [],\n",
        "    'Best Epoch': []\n",
        "}\n",
        "\n",
        "for name, accuracies in results.items():\n",
        "    summary_table['Model'].append(name)\n",
        "    summary_table['Final Train Accuracy (%)'].append(f\"{accuracies['train'][-1]:.2f}\")\n",
        "    summary_table['Final Test Accuracy (%)'].append(f\"{accuracies['test'][-1]:.2f}\")\n",
        "    summary_table['Best Epoch'].append(accuracies['best_epoch'])\n",
        "\n",
        "print(\"\\nSummary Table:\")\n",
        "print(f\"{'Model':<20} {'Final Train Accuracy (%)':<25} {'Final Test Accuracy (%)':<25} {'Best Epoch':<15}\")\n",
        "print(\"-\" * 85)\n",
        "for i in range(len(summary_table['Model'])):\n",
        "    print(f\"{summary_table['Model'][i]:<20} {summary_table['Final Train Accuracy (%)'][i]:<25} {summary_table['Final Test Accuracy (%)'][i]:<25} {summary_table['Best Epoch'][i]:<15}\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "xHTaQhPR8vW0",
        "outputId": "7a808d60-0aab-425f-89c0-b18f53cc9337"
      },
      "execution_count": 18,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Training Base Model model:\n",
            "Epoch [1/20], Train Accuracy: 78.30%, Test Accuracy: 83.00%\n",
            "Epoch [2/20], Train Accuracy: 86.68%, Test Accuracy: 85.83%\n",
            "Epoch [3/20], Train Accuracy: 88.61%, Test Accuracy: 87.24%\n",
            "Epoch [4/20], Train Accuracy: 89.48%, Test Accuracy: 88.74%\n",
            "Epoch [5/20], Train Accuracy: 90.36%, Test Accuracy: 88.86%\n",
            "Epoch [6/20], Train Accuracy: 90.77%, Test Accuracy: 89.69%\n",
            "Epoch [7/20], Train Accuracy: 91.38%, Test Accuracy: 89.83%\n",
            "Epoch [8/20], Train Accuracy: 91.76%, Test Accuracy: 90.22%\n",
            "Epoch [9/20], Train Accuracy: 92.24%, Test Accuracy: 90.27%\n",
            "Epoch [10/20], Train Accuracy: 92.66%, Test Accuracy: 90.16%\n",
            "Epoch [11/20], Train Accuracy: 93.00%, Test Accuracy: 90.23%\n",
            "Epoch [12/20], Train Accuracy: 93.40%, Test Accuracy: 90.69%\n",
            "Epoch [13/20], Train Accuracy: 93.72%, Test Accuracy: 90.54%\n",
            "Epoch [14/20], Train Accuracy: 94.01%, Test Accuracy: 90.06%\n",
            "Epoch [15/20], Train Accuracy: 94.28%, Test Accuracy: 90.48%\n",
            "Epoch [16/20], Train Accuracy: 94.60%, Test Accuracy: 90.58%\n",
            "Epoch [17/20], Train Accuracy: 94.75%, Test Accuracy: 90.08%\n",
            "Epoch [18/20], Train Accuracy: 95.07%, Test Accuracy: 90.24%\n",
            "Epoch [19/20], Train Accuracy: 95.41%, Test Accuracy: 89.75%\n",
            "Epoch [20/20], Train Accuracy: 95.65%, Test Accuracy: 90.26%\n",
            "Best model for Base Model saved with test accuracy: 90.69% at epoch 12\n",
            "\n",
            "Training Dropout model:\n",
            "Epoch [1/20], Train Accuracy: 69.71%, Test Accuracy: 81.76%\n",
            "Epoch [2/20], Train Accuracy: 81.55%, Test Accuracy: 85.21%\n",
            "Epoch [3/20], Train Accuracy: 84.46%, Test Accuracy: 86.91%\n",
            "Epoch [4/20], Train Accuracy: 85.68%, Test Accuracy: 87.52%\n",
            "Epoch [5/20], Train Accuracy: 86.49%, Test Accuracy: 87.92%\n",
            "Epoch [6/20], Train Accuracy: 87.20%, Test Accuracy: 88.41%\n",
            "Epoch [7/20], Train Accuracy: 87.75%, Test Accuracy: 88.37%\n",
            "Epoch [8/20], Train Accuracy: 88.17%, Test Accuracy: 88.90%\n",
            "Epoch [9/20], Train Accuracy: 88.47%, Test Accuracy: 89.30%\n",
            "Epoch [10/20], Train Accuracy: 88.89%, Test Accuracy: 89.12%\n",
            "Epoch [11/20], Train Accuracy: 89.02%, Test Accuracy: 89.60%\n",
            "Epoch [12/20], Train Accuracy: 89.17%, Test Accuracy: 89.44%\n",
            "Epoch [13/20], Train Accuracy: 89.46%, Test Accuracy: 89.71%\n",
            "Epoch [14/20], Train Accuracy: 89.55%, Test Accuracy: 89.88%\n",
            "Epoch [15/20], Train Accuracy: 89.81%, Test Accuracy: 89.91%\n",
            "Epoch [16/20], Train Accuracy: 89.97%, Test Accuracy: 89.85%\n",
            "Epoch [17/20], Train Accuracy: 90.02%, Test Accuracy: 89.86%\n",
            "Epoch [18/20], Train Accuracy: 90.15%, Test Accuracy: 89.86%\n",
            "Epoch [19/20], Train Accuracy: 90.23%, Test Accuracy: 90.24%\n",
            "Epoch [20/20], Train Accuracy: 90.52%, Test Accuracy: 89.66%\n",
            "Best model for Dropout saved with test accuracy: 90.24% at epoch 19\n",
            "\n",
            "Training Weight Decay model:\n",
            "Epoch [1/20], Train Accuracy: 79.15%, Test Accuracy: 85.21%\n",
            "Epoch [2/20], Train Accuracy: 87.20%, Test Accuracy: 86.34%\n",
            "Epoch [3/20], Train Accuracy: 88.86%, Test Accuracy: 88.21%\n",
            "Epoch [4/20], Train Accuracy: 89.65%, Test Accuracy: 89.18%\n",
            "Epoch [5/20], Train Accuracy: 90.54%, Test Accuracy: 89.46%\n",
            "Epoch [6/20], Train Accuracy: 90.81%, Test Accuracy: 89.79%\n",
            "Epoch [7/20], Train Accuracy: 91.52%, Test Accuracy: 89.40%\n",
            "Epoch [8/20], Train Accuracy: 91.80%, Test Accuracy: 90.33%\n",
            "Epoch [9/20], Train Accuracy: 92.37%, Test Accuracy: 89.84%\n",
            "Epoch [10/20], Train Accuracy: 92.46%, Test Accuracy: 90.33%\n",
            "Epoch [11/20], Train Accuracy: 92.93%, Test Accuracy: 90.42%\n",
            "Epoch [12/20], Train Accuracy: 93.21%, Test Accuracy: 90.49%\n",
            "Epoch [13/20], Train Accuracy: 93.54%, Test Accuracy: 90.18%\n",
            "Epoch [14/20], Train Accuracy: 93.89%, Test Accuracy: 90.24%\n",
            "Epoch [15/20], Train Accuracy: 94.07%, Test Accuracy: 90.12%\n",
            "Epoch [16/20], Train Accuracy: 94.44%, Test Accuracy: 90.44%\n",
            "Epoch [17/20], Train Accuracy: 94.55%, Test Accuracy: 90.79%\n",
            "Epoch [18/20], Train Accuracy: 94.89%, Test Accuracy: 90.55%\n",
            "Epoch [19/20], Train Accuracy: 95.18%, Test Accuracy: 90.57%\n",
            "Epoch [20/20], Train Accuracy: 95.27%, Test Accuracy: 90.01%\n",
            "Best model for Weight Decay saved with test accuracy: 90.79% at epoch 17\n",
            "\n",
            "Training Batch Normalization model:\n",
            "Epoch [1/20], Train Accuracy: 83.07%, Test Accuracy: 87.21%\n",
            "Epoch [2/20], Train Accuracy: 88.54%, Test Accuracy: 87.04%\n",
            "Epoch [3/20], Train Accuracy: 89.62%, Test Accuracy: 89.40%\n",
            "Epoch [4/20], Train Accuracy: 90.61%, Test Accuracy: 89.69%\n",
            "Epoch [5/20], Train Accuracy: 91.23%, Test Accuracy: 89.63%\n",
            "Epoch [6/20], Train Accuracy: 91.72%, Test Accuracy: 90.27%\n",
            "Epoch [7/20], Train Accuracy: 92.25%, Test Accuracy: 89.97%\n",
            "Epoch [8/20], Train Accuracy: 92.56%, Test Accuracy: 90.55%\n",
            "Epoch [9/20], Train Accuracy: 92.88%, Test Accuracy: 90.59%\n",
            "Epoch [10/20], Train Accuracy: 93.34%, Test Accuracy: 90.68%\n",
            "Epoch [11/20], Train Accuracy: 93.75%, Test Accuracy: 89.69%\n",
            "Epoch [12/20], Train Accuracy: 94.02%, Test Accuracy: 90.54%\n",
            "Epoch [13/20], Train Accuracy: 94.26%, Test Accuracy: 90.48%\n",
            "Epoch [14/20], Train Accuracy: 94.70%, Test Accuracy: 90.88%\n",
            "Epoch [15/20], Train Accuracy: 94.93%, Test Accuracy: 90.53%\n",
            "Epoch [16/20], Train Accuracy: 95.08%, Test Accuracy: 90.72%\n",
            "Epoch [17/20], Train Accuracy: 95.48%, Test Accuracy: 90.82%\n",
            "Epoch [18/20], Train Accuracy: 95.74%, Test Accuracy: 90.19%\n",
            "Epoch [19/20], Train Accuracy: 95.85%, Test Accuracy: 90.39%\n",
            "Epoch [20/20], Train Accuracy: 96.15%, Test Accuracy: 89.76%\n",
            "Best model for Batch Normalization saved with test accuracy: 90.88% at epoch 14\n",
            "\n",
            "Summary Table:\n",
            "Model                Final Train Accuracy (%)  Final Test Accuracy (%)   Best Epoch     \n",
            "-------------------------------------------------------------------------------------\n",
            "Base Model           95.65                     90.26                     12             \n",
            "Dropout              90.52                     89.66                     19             \n",
            "Weight Decay         95.27                     90.01                     17             \n",
            "Batch Normalization  96.15                     89.76                     14             \n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import files\n",
        "!zip -r /content/saved_models.zip /content/saved_models\n",
        "files.download('saved_models.zip')"
      ],
      "metadata": {
        "id": "MxJey9eaIUxX"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "AAbHoAHIIxq-"
      },
      "execution_count": null,
      "outputs": []
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "gpuType": "L4",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}